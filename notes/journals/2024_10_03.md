- Listening to [[Learn French with Paul Noble for Beginners - Complete Course]]
	- There is less and less advice and more and more exercising the sentence structures. Past tense has been introduced with the focus on regular verbs, but with a few most common irregular ones in the mix too.
- Listening to [[Supremacy]]
	- Chapter 12 - Myth Busters
		- [[Quote]]:  One of the most powerful features of artificial intelligence isn't so much what it can do, but how it exists in the human imagination. As human inventions go it is unique. No other technology has been design to replicate the mind itself and so its pursuit is wrapped in ideas that border on fantastical.
		- In June 2022 [[Blake Lemoine]], a software engineer at [[Google]] make headlines when he said publicly that Google's LaMDA is sentient. He came to the conclusion after hours of conversations with the model as part of his research into the ethics of AI. During the discussions the chatbot asked for a lawyer. As a result Lemoine came to his conclusion that under the 13th amendment of the US constitution the AI system is a person. He was promptly fired for violation of contract - relating to safeguarding proprietary information.
		- During the pandemic chatbots became popular companions, especially the [[Replika]] (started by [[Eugenia Kuyda]]). Many people, even if sceptical at first, form strong emotional reactions to chatbots. Some of them making big life decisions, like buying and selling houses and moving between states to deliver on the AI requests.
		- [[Quote]]: Michael and Noreen's experience has shown that chatbots can offer much needed comfort. But they also laid bare how much human beings can be steered by algorithms.
		- One of the problems with large language models is that they are trained on what is popular and available on the internet, and so it is primarily an English perspective, one, expressed in language people are often not comfortable expressing face to face. Sensational topics and opinions often get more cover, and so are over-represented, while minority views, even if valid, are drowned in the noise. Now that the AI has been trained one such  body of text, its inherent biases will be strengthen as the new content generated will most likely generate views aligned to those already most prevalent. This will polarise many topics, including the politics and progress globalisation further.
		- [[Emily Menon Bender]] is a linguistics professor at the [[University of Washington]] specialising in [[Computational Linguistics]]. She got involved in the debate as she noticed that the linguistics are moving away from understanding the language without its core - human to human interactions. The focus was shifting towards mathematical analysis and human to computer interactions. She was publicly sceptical about AI understanding anything.
		- LATER [[On the Dangers of Stochastic Parrots: Can Language Models Be Too Big]] - paper written by [[Emily Menon Bender]], [[Timnit Gebru]] and others, published in March 2021.
		- The Stochastic Parrots paper got Timnit Gebru fired from Google.
	- Chapter 13 - Hello, ChatGPT
		- [[Quote]]: Some jobs are going to go away [Altman]([[Sam Altman]]) said bluntly in one interview. There will be new, better jobs which are difficult to imagine today. This was met with a quiet resignation among press and general public because historic shifts like the industrial revolution had could that technology cUld indeed bring painful changes to employment.
		  And Generative AI like [[ChatGPT]] were not flush in the pan like [[Crypto]].
		- Google realised the threat OpenAI posed and that despite most of the important discoveries, including the transformers, came from its research, others were overtaking them, capitalising on their research and threatening Google's ads-in-search business model. Google was too big. It had LaMDA and Meena - its chatbot before others, but considered it too dangerous to the reputation to use it.
		- [[Quote]]: From the outset none of this made sense. [[Google]] had done everything early. Its researchers had invented the transformer. And they have created the sophisticated language model - [[LaMDA]] - years before GPT 4. Its own AI lab - [[DeepMind]] - had set off on a mission to  build AGI five years before [[OpenAI]] had even been founded to do the same. Yet Google was now racing to catch up. Its lumbering bureaucracy and fear of disrupting its business and reputation has set a deep inertia.