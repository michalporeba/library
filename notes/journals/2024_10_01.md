- Listening to [[Supremacy]]
	- Chapter 10 - Size Matters
		- The struggle of how to contribute to humanity made OpenAI from being open, non-for profit, through thinking earn-to-give concepts, to starting partnership with Microsoft, but with a limit to stop licensing the technology once Artificial General Intelligence level is achieved.
		- [[Quote]]: Altman's new company was doing a complicated dance around its core tenants. Including the ones in its 2018 charter. Having pledged not to help concentrate power with its AI it was now helping one of the world's most powerful tech companies becoming more powerful. 
		  After promising to help other projects on the brink of AGI because that journey should not be competitive. It would instead spark a global arms race in which companies and developers would churn out AI systems more haphazardly than ever before. And as it clamped down on details of each new language model it prepared to release. Open AI was closing itself off from outside scrutiny. It's name was a source of amusement among sceptical academics and worried ai researchers. Altman and Brockman seemed to justify their change of direction in two ways:
		  First, pivoting as you sped along was the typical path of a startup. Second, the goal of AGI was more important than the specific means of getting there. Maybe they had to break some promises along the way. But humanity would be better for it in the end.
		- [[Quote]]: Big tech's apologists have argued for years that their technology empowers the world, dispersing more value to people than even the trillions of dollars those companies earn financially. It's true that smart phones and social media unlocked easy ways to connect to others across the globe and new forms of entertainment and business. Apps, like Google Maps, and Facebook are free to use and full of nifty features that make our lives seems more convenient. But new technology has came with the price. From the loss of the human connection and privacy to the rise of screen-time addiction, mental health problems, political polarisation, and income inequality from greater automatisation. All powered by a handful of companies. Open AI was ushering in another big shift in how people used technology. Similar to the one Facebook sparked with social media.
		  And aligning himself with [[Microsoft]] meant that [Altman]([[Sam Altman]]) was setting up his company to repeat history in much the same way [[Mark Zuckerberg]] had. Zuckerberg's creation had caused damage because his business model incentifised eyeballs glued to screens. The pandoras box of side-effects was already breaming. There was legacy of problems with racial and gender bias in artifical intelligence systems. AI already kept people addicted to the social media feeds on their screens. And there loomed potential catastrophic impact on jobs.
	- Chapter 11 - Bound to Big Tech
		- [[OpenAI]] moved from an open idea to improve humanity, to for profit organisation supporting [[Microsoft]]. But people working at OpenAI appeared to be sold on the idea, that being first to AGI s more important than sticking to the openness.
		- Open AI had access to a new Microsoft supercomputer with 10,000 GPUs.
		- [[Reddit]] went on to become one of the most important sources of data for training OpenAI models after Facebook closed access to its data after the scandal with [[Cambridge Analytica]]
		- Big tech was monopolising AI development. [[Quote]]: A 2023 study by MIT found that large companies had come to dominate ownership of AI models over the last decade. From controlling 11% of them in 2010 to nearly all of them, 96%, in 2021. Even government projects looked puny when compared to the enormous amounts of money that big tech was pouring into AI. In 2021, for instance, US Government agencies who were not involved in defence had budgeted 1.5 billion dollars to AI. The private sector, meanwhile, had poured 350 billion dollars into the field that same year.
		- LATER [[Dario Amodei]] [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565)
		- [[Dario Amodei]] worked at [[OpenAI]] but quit over his concerns over AI safety. He then started company [[Anthropic]] to move AI in a safer direction as a Public Benefit Corporation.
		- [[Jaan Tallinn]] has come up in the story a number of times already. He was investing in the AI projects from the concern over the direction. He was one of the founders of [[Anthropic]]. After investing in a number of companies, he later said that he regretted helping to stoke so much competition in AI making it potentially more dangerous.
		- Amodei, two years after leaving OpenAi because of its commercial ties with Microsoft, took 6 billion dollars from Google and Amazon, aligning himself with both companies.
		- [[Mustafa Suleyman]] - cofounder of [[DeepMind]] who set up partnership with a number of hospitals in England and [[DeepMind]] to help doctors and nurses to help real life problems in addition to pursuing [[Demis Hassabis]]' obsession with game simulation. Because of the medical regulations, they couldn't used the [[DeepMind]] technology, but they used the knowledge and their data scientists to work on predicting acute kidney injury in patients. The doctors were happy with the results, but after the media reported that Google is getting access to sensitive patient data, it all stopped. It has shown that the links to Google are not all that good, and may stop progress in making use of AI in applications beyond advertisement. Despite that, and attempts at self regulation, Suleyman's effort failed. Google, on the other hand, started their own medical division of AI.